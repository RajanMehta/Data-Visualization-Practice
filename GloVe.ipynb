{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajanMehta/practice-libraries/blob/master/GloVe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWnqj6WB5HJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4114f79a-4ae8-4cd8-a21e-19e8687c01d7"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-29 15:57:10--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-09-29 15:57:11--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-09-29 15:57:11--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  19.3MB/s    in 43s     \n",
            "\n",
            "2019-09-29 15:57:55 (18.9 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGz_uPybvW0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "75e8d473-7c81-4a9d-c5ed-c2f0953e35e5"
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geXRZ4BA505i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "12ab3156-400a-4f1f-8747-4d91981bece3"
      },
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   sample_data\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Hl7XEIy9jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def loadGloveModel(gloveFile):\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(gloveFile,'r')\n",
        "    model = {}\n",
        "    for line in f:\n",
        "        splitLine = line.split()\n",
        "        word = splitLine[0]\n",
        "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
        "        model[word] = embedding\n",
        "    print(\"Done.\",len(model),\" words loaded!\")\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLpggi-ty-31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f1256e63-59a3-4ce0-ba96-e0a4c774eea5"
      },
      "source": [
        "model = loadGloveModel('glove.6B.300d.txt')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "Done. 400000  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvq8yIbZzgpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f460a538-ab76-4998-fdf6-33d8344e0aae"
      },
      "source": [
        "model['banana'].shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbCvhZcC6JlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similar_words(embed,text,refs,thresh):\n",
        "\n",
        "    C = np.zeros((len(refs),300))\n",
        "\n",
        "    for idx, term in enumerate(refs):\n",
        "        if term in embed:\n",
        "            C[idx] = embed[term]\n",
        "\n",
        "\n",
        "    tokens = text.split(' ')\n",
        "    scores = [0.] * len(tokens)\n",
        "    found=[]\n",
        "\n",
        "    for idx, term in enumerate(tokens):\n",
        "        if term in embed:\n",
        "            vec = embed[term]\n",
        "            cosines = np.dot(C,vec.T)\n",
        "            score = np.mean(cosines)\n",
        "            scores[idx] = score\n",
        "            if (score > thresh):\n",
        "                found.append(term)\n",
        "    print(scores)\n",
        "\n",
        "    return found"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehvW-OL-6L-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "91adbe02-39d2-4228-aa86-58b6c0f6cef6"
      },
      "source": [
        "cuisine_refs = [\"mexican\",\"chinese\",\"french\",\"british\",\"american\"]\n",
        "threshold = 15\n",
        "\n",
        "text = \"I want to find an indian restaurant\"\n",
        "\n",
        "cuisines = find_similar_words(model,text,cuisine_refs,threshold)\n",
        "print(cuisines)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 10.41394751500477, 11.723124558513849, 8.628884023494864, 14.14132090389523, 19.96173691301264, 9.441536971841385]\n",
            "['indian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_qA9-M2BlZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0hMShT2Blcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "05c3a250-80af-4046-fb17-2f5210ee894a"
      },
      "source": [
        "def sum_vecs(embed,text):\n",
        "\n",
        "    tokens = text.split(' ')\n",
        "    vec = np.zeros(300)\n",
        "\n",
        "    for idx, term in enumerate(tokens):\n",
        "        if term in embed:\n",
        "            vec = vec + embed[term]\n",
        "    return vec\n",
        "\n",
        "\n",
        "def get_centroid(embed,examples):\n",
        "\n",
        "    C = np.zeros((len(examples),300))\n",
        "    for idx, text in enumerate(examples):\n",
        "        C[idx,:] = sum_vecs(embed,text)\n",
        "\n",
        "    centroid = np.mean(C,axis=0)\n",
        "    assert centroid.shape[0] == 300\n",
        "    return centroid\n",
        "\n",
        "\n",
        "def get_intent(embed,text):\n",
        "    intents = ['deny', 'inform', 'greet']\n",
        "    vec = sum_vecs(embed,text)\n",
        "    scores = np.array([ np.linalg.norm(vec-data[label][\"centroid\"]) for label in intents ])\n",
        "    return intents[np.argmin(scores)]\n",
        "\n",
        "\n",
        "data={\n",
        "  \"greet\": {\n",
        "    \"examples\" : [\"hello\",\"hey there\",\"howdy\",\"hello\",\"hi\",\"hey\",\"hey ho\"],\n",
        "    \"centroid\" : None\n",
        "  },\n",
        "  \"inform\": {\n",
        "    \"examples\" : [\n",
        "      \"i'd like something asian\",\n",
        "      \"maybe korean\",\n",
        "      \"what mexican options do i have\",\n",
        "      \"what italian options do i have\",\n",
        "      \"i want korean food\",\n",
        "      \"i want german food\",\n",
        "      \"i want vegetarian food\",\n",
        "      \"i would like chinese food\",\n",
        "      \"i would like indian food\",\n",
        "      \"what japanese options do i have\",\n",
        "      \"korean please\",\n",
        "      \"what about indian\",\n",
        "      \"i want some vegan food\",\n",
        "      \"maybe thai\",\n",
        "      \"i'd like something vegetarian\",\n",
        "      \"show me french restaurants\",\n",
        "      \"show me a cool malaysian spot\"\n",
        "    ],\n",
        "    \"centroid\" : None\n",
        "  },\n",
        "  \"deny\": {\n",
        "    \"examples\" : [\n",
        "      \"nah\",\n",
        "      \"any other places ?\",\n",
        "      \"anything else\",\n",
        "      \"no thanks\"\n",
        "      \"not that one\",\n",
        "      \"i do not like that place\",\n",
        "      \"something else please\",\n",
        "      \"no please show other options\"\n",
        "    ],\n",
        "    \"centroid\" : None\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "for label in data.keys():\n",
        "    data[label][\"centroid\"] = get_centroid(model,data[label][\"examples\"])\n",
        "\n",
        "\n",
        "for text in [\"hey you\",\"i am looking for chinese food\",\"not for me\"]:\n",
        "    print(\"text : '{0}', predicted_label : '{1}'\".format(text,get_intent(model,text)))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text : 'hey you', predicted_label : 'greet'\n",
            "text : 'i am looking for chinese food', predicted_label : 'inform'\n",
            "text : 'not for me', predicted_label : 'deny'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}