{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextRank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjIIXCF8uNZ5eD44s1gp+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajanMehta/mini-projects/blob/master/TextRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMmBDchjXRmc",
        "colab_type": "text"
      },
      "source": [
        "### **Document Summarization using TextRank**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-2VVkzlNj2h",
        "colab_type": "code",
        "outputId": "6f623fcb-e5e6-425e-9252-8772874b5f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "document = \"\"\"To Sherlock Holmes she is always the woman. I have\n",
        "seldom heard him mention her under any other name. In his eyes she\n",
        "eclipses and predominates the whole of her sex. It was not that he\n",
        "felt any emotion akin to love for Irene Adler. All emotions, and that\n",
        "one particularly, were abhorrent to his cold, precise but admirably\n",
        "balanced mind. He was, I take it, the most perfect reasoning and\n",
        "observing machine that the world has seen, but as a lover he would\n",
        "have placed himself in a false position. He never spoke of the softer\n",
        "passions, save with a gibe and a sneer. They were admirable things for\n",
        "the observer-excellent for drawing the veil from menâ€™s motives and\n",
        "actions. But for the trained reasoner to admit such intrusions into\n",
        "his own delicate and finely adjusted temperament was to introduce a\n",
        "distracting factor which might throw a doubt upon all his mental\n",
        "results. Grit in a sensitive instrument, or a crack in one of his own\n",
        "high-power lenses, would not be more disturbing than a strong emotion\n",
        "in a nature such as his. And yet there was but one woman to him, and\n",
        "that woman was the late Irene Adler, of dubious and questionable\n",
        "memory.\n",
        "\"\"\"\n",
        "\n",
        "# sentence splitting\n",
        "document = ' '.join(document.strip().split('\\n'))\n",
        "sentence_tokenizer = PunktSentenceTokenizer()\n",
        "sentences = sentence_tokenizer.tokenize(document)\n",
        "\n",
        "# bag of words\n",
        "c = CountVectorizer()\n",
        "bow_matrix = c.fit_transform(sentences)\n",
        "bow_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11x127 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 183 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5-cI1vgSg-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize matrix. This will re-weight each word based upon its tf-idf, which will diminish the effect of words common to each sentence.\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "normalized_matrix = TfidfTransformer().fit_transform(bow_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB_0t9-cTWkG",
        "colab_type": "code",
        "outputId": "85ee1972-ed07-4756-cbd0-058f8d089b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# converting to graph\n",
        "# This is a mirrored matrix, where both the rows and columns correspond to sentences, \n",
        "# and the elements describe how similar the two sentences are. Scores of 1 mean that the sentences are exactly the same, \n",
        "# while scores of 0 mean the sentences have no overlap.\n",
        "\n",
        "similarity_graph = normalized_matrix * normalized_matrix.T\n",
        "similarity_graph.toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.13737879, 0.04767903, 0.04305016,\n",
              "        0.04345599, 0.03330044, 0.05261648, 0.07798958, 0.        ,\n",
              "        0.20047419],\n",
              "       [0.        , 1.        , 0.0842143 , 0.07819597, 0.        ,\n",
              "        0.05171612, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.05807146],\n",
              "       [0.13737879, 0.0842143 , 1.        , 0.        , 0.07004069,\n",
              "        0.09648614, 0.1069042 , 0.06701793, 0.09437203, 0.20474295,\n",
              "        0.1197599 ],\n",
              "       [0.04767903, 0.07819597, 0.        , 1.        , 0.07558987,\n",
              "        0.18678911, 0.05853972, 0.09249592, 0.10892262, 0.09110741,\n",
              "        0.24159019],\n",
              "       [0.04305016, 0.        , 0.07004069, 0.07558987, 1.        ,\n",
              "        0.07055583, 0.02370685, 0.07272032, 0.17253418, 0.08262451,\n",
              "        0.17789849],\n",
              "       [0.04345599, 0.05171612, 0.09648614, 0.18678911, 0.07055583,\n",
              "        1.        , 0.12952649, 0.06859301, 0.06837492, 0.13015945,\n",
              "        0.15423071],\n",
              "       [0.03330044, 0.        , 0.1069042 , 0.05853972, 0.02370685,\n",
              "        0.12952649, 1.        , 0.06307559, 0.03194234, 0.02852116,\n",
              "        0.11271501],\n",
              "       [0.05261648, 0.        , 0.06701793, 0.09249592, 0.07272032,\n",
              "        0.06859301, 0.06307559, 1.        , 0.09411725, 0.        ,\n",
              "        0.07702234],\n",
              "       [0.07798958, 0.        , 0.09437203, 0.10892262, 0.17253418,\n",
              "        0.06837492, 0.03194234, 0.09411725, 1.        , 0.12388421,\n",
              "        0.14327969],\n",
              "       [0.        , 0.        , 0.20474295, 0.09110741, 0.08262451,\n",
              "        0.13015945, 0.02852116, 0.        , 0.12388421, 1.        ,\n",
              "        0.04706138],\n",
              "       [0.20047419, 0.05807146, 0.1197599 , 0.24159019, 0.17789849,\n",
              "        0.15423071, 0.11271501, 0.07702234, 0.14327969, 0.04706138,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0u160GqT_L5",
        "colab_type": "code",
        "outputId": "4f9beb24-5c85-44d0-a076-77798b8cf60a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Pagerank\n",
        "import networkx as nx\n",
        "nx_graph = nx.from_scipy_sparse_matrix(similarity_graph)\n",
        "scores = nx.pagerank(nx_graph)\n",
        "scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.08385008597047353,\n",
              " 1: 0.07528144170324103,\n",
              " 2: 0.09838560290878211,\n",
              " 3: 0.09744270669005967,\n",
              " 4: 0.0892656646614313,\n",
              " 5: 0.09825615495072643,\n",
              " 6: 0.0826112264425111,\n",
              " 7: 0.08271845324598913,\n",
              " 8: 0.09433617163509286,\n",
              " 9: 0.08636822789376782,\n",
              " 10: 0.11148426389792515}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDrXV7H-Wz4r",
        "colab_type": "code",
        "outputId": "cd31303d-c4fd-4f64-e5e6-a87b856cd512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ranked = sorted(((scores[i],s) for i,s in enumerate(sentences)),\n",
        "                reverse=True)\n",
        "print(ranked[0][0])\n",
        "ranked[0][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.11148426389792515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgwAw1MJXp4-",
        "colab_type": "code",
        "outputId": "f49096eb-7983-469a-f06c-c7f0bb464606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "### Combine all of this into a function ###\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        " \n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        " \n",
        "def textrank(document):\n",
        "    sentence_tokenizer = PunktSentenceTokenizer()\n",
        "    sentences = sentence_tokenizer.tokenize(document)\n",
        " \n",
        "    bow_matrix = CountVectorizer().fit_transform(sentences)\n",
        "    normalized = TfidfTransformer().fit_transform(bow_matrix)\n",
        " \n",
        "    similarity_graph = normalized * normalized.T\n",
        " \n",
        "    nx_graph = nx.from_scipy_sparse_matrix(similarity_graph)\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "    return sorted(((scores[i],s) for i,s in enumerate(sentences)),\n",
        "                  reverse=True)\n",
        "\n",
        "textrank(document)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.11148426389792515,\n",
              "  'And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.'),\n",
              " (0.09838560290878211,\n",
              "  'In his eyes she eclipses and predominates the whole of her sex.'),\n",
              " (0.09825615495072643,\n",
              "  'He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position.'),\n",
              " (0.09744270669005967,\n",
              "  'It was not that he felt any emotion akin to love for Irene Adler.'),\n",
              " (0.09433617163509286,\n",
              "  'But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results.'),\n",
              " (0.0892656646614313,\n",
              "  'All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.'),\n",
              " (0.08636822789376782,\n",
              "  'Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his.'),\n",
              " (0.08385008597047353, 'To Sherlock Holmes she is always the woman.'),\n",
              " (0.08271845324598913,\n",
              "  'They were admirable things for the observer-excellent for drawing the veil from menâ€™s motives and actions.'),\n",
              " (0.0826112264425111,\n",
              "  'He never spoke of the softer passions, save with a gibe and a sneer.'),\n",
              " (0.07528144170324103,\n",
              "  'I have seldom heard him mention her under any other name.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}